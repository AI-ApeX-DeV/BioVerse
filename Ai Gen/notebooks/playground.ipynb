{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    response = requests.post(API_URL, headers=headers, data=data)\n",
    "    return response.json()\n",
    "\n",
    "output = query(\"C:/Users/shrey/OneDrive/Desktop/EthMumbai/artifacts/WhatsApp Image 2024-03-30 at 23.55.54_61b8d6ba.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': 'people sitting at tables in a large room with a ceiling'}\n"
     ]
    }
   ],
   "source": [
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can't touch this :ceiling:\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "\n",
    "# API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "# headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "# def query(filename):\n",
    "#     with open(filename, \"rb\") as f:\n",
    "#         data = f.read()\n",
    "#     response = requests.post(API_URL, headers=headers, data=data)\n",
    "#     return response.json()\n",
    "\n",
    "# output = query(\"C:/Users/shrey/OneDrive/Pictures/IMG_7355.JPG\")\n",
    "\n",
    "# Used to securely store your API key\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "genai.configure(api_key='AIzaSyBa5b8ZuK83ehPi52ua4Ly724ofJHTT5Zk')\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "response = model.generate_content(f\"You are a Indian meme expert, you can generate short sarcastic meme captions from descriptions. Here is my description:'''{output[0]['generated_text']}'''\")\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"C:/Users/shrey/OneDrive/Desktop/EthMumbai/artifacts/WhatsApp Image 2024-03-30 at 23.55.54_61b8d6ba.jpg\")\n",
    "\n",
    "# Define text to be drawn\n",
    "text = response.text\n",
    "\n",
    "# Calculate font scale based on image width\n",
    "font_scale = image.shape[1] / 1000  # Adjust divisor as needed\n",
    "\n",
    "# Choose font\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Determine text size\n",
    "text_size, _ = cv2.getTextSize(text, font, font_scale, thickness=2)\n",
    "\n",
    "# Calculate text position (centered at the top)\n",
    "text_x = (image.shape[1] - text_size[0]) // 2\n",
    "text_y = text_size[1] + 50  # Adjust the value to position the text\n",
    "\n",
    "# Add white outline to the text\n",
    "cv2.putText(image, text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "# Add white font to the text (thinner)\n",
    "cv2.putText(image, text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness=3, lineType=cv2.LINE_AA)\n",
    "\n",
    "# Save the image with the text\n",
    "cv2.imwrite(\"output.png\", image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"C:/Users/shrey/OneDrive/Desktop/EthMumbai/artifacts/WhatsApp Image 2024-03-30 at 23.55.54_61b8d6ba.jpg\")\n",
    "\n",
    "# Define text to be drawn\n",
    "text = response.text\n",
    "\n",
    "# Calculate font scale based on image width\n",
    "font_scale = image.shape[1] / 800  # Adjust divisor as needed for a larger text size\n",
    "\n",
    "# Choose font\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Determine text size\n",
    "text_size, _ = cv2.getTextSize(text, font, font_scale, thickness=2)\n",
    "\n",
    "# Calculate text position (centered at the top)\n",
    "text_x = (image.shape[1] - text_size[0]) // 2\n",
    "text_y = text_size[1] + 50  # Adjust the value to position the text\n",
    "\n",
    "# Add drop shadow effect (black outline)\n",
    "shadow_offset = 2\n",
    "cv2.putText(image, text, (text_x + shadow_offset, text_y + shadow_offset), font, font_scale, (0, 0, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "# Add white font to the text\n",
    "cv2.putText(image, text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "# Save the image with the text\n",
    "cv2.imwrite(\"output.png\", image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You can't touch this :ceiling:\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"C:/Users/shrey/OneDrive/Desktop/EthMumbai/artifacts/WhatsApp Image 2024-03-30 at 23.55.54_61b8d6ba.jpg\")\n",
    "\n",
    "# Define text to be drawn\n",
    "text = response.text\n",
    "\n",
    "# Choose font scale and thickness\n",
    "font_scale = 5  # Increase the font scale for larger text\n",
    "outline_thickness = 50  # Thickness for the black outline\n",
    "font_thickness = 5\n",
    "\n",
    "# Choose text color in BGR format (here, white for the font)\n",
    "text_color = (255, 255, 255)\n",
    "\n",
    "# Choose text color in BGR format (here, black for the outline)\n",
    "outline_color = (0, 0, 0)\n",
    "\n",
    "# Load font (provide the path to your font file)\n",
    "font_path = \"path/to/ant1.ttf\"  # Replace with the actual path to your font file\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Determine text size\n",
    "text_size, _ = cv2.getTextSize(text, font, font_scale, outline_thickness)\n",
    "\n",
    "# Calculate text position (centered at the top)\n",
    "text_x = (image.shape[1] - text_size[0]) // 2\n",
    "text_y = text_size[1] + 50  # Adjust the value to position the text\n",
    "\n",
    "# Add black outline to the text\n",
    "cv2.putText(image, text, (text_x, text_y), font, font_scale, outline_color, thickness=outline_thickness)\n",
    "\n",
    "# Add white font to the text\n",
    "cv2.putText(image, text, (text_x, text_y), font, font_scale, text_color, thickness=font_thickness)\n",
    "\n",
    "# Save the image with the text\n",
    "cv2.imwrite(\"output.png\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT Crowd: Laptop squad assemble!\n"
     ]
    }
   ],
   "source": [
    "# Used to securely store your API key\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "genai.configure(api_key='AIzaSyBa5b8ZuK83ehPi52ua4Ly724ofJHTT5Zk')\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "response = model.generate_content(f\"this is the description for photo '''{output[0]['generated_text']}''' write a 5- 10 word meme for it humor should be very nice\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = request.files[\"image\"]\n",
    "image_file = image.read()\n",
    "image_size = 350\n",
    "image = load_demo_image(image_file, image_size=image_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageDraw' object has no attribute 'textsize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mtruetype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marial.ttf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m36\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Determine text size\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m text_width, text_height \u001b[38;5;241m=\u001b[39m draw\u001b[38;5;241m.\u001b[39mtextsize(text, font\u001b[38;5;241m=\u001b[39mfont)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate text position (centered)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m image_width, image_height \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39msize\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ImageDraw' object has no attribute 'textsize'"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(\"C:/Users/shrey/OneDrive/Pictures/IMG_7355.JPG\")\n",
    "\n",
    "# Initialize the drawing context\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define text to be drawn\n",
    "text = \"Sample Text\"\n",
    "\n",
    "# Choose a font (adjust the path to your font file as necessary)\n",
    "font = ImageFont.truetype(\"arial.ttf\", 36)\n",
    "\n",
    "# Determine text size\n",
    "text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "# Calculate text position (centered)\n",
    "image_width, image_height = image.size\n",
    "text_x = (image_width - text_width) // 2\n",
    "text_y = (image_height - text_height) // 2\n",
    "\n",
    "# Set text color\n",
    "text_color = (255, 255, 255)  # White\n",
    "\n",
    "# Draw text on image\n",
    "draw.text((text_x, text_y), text, fill=text_color, font=font)\n",
    "\n",
    "# Save or display the image\n",
    "image.save(\"output.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.174.47:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask_cors import CORS\n",
    "import io\n",
    "import json\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from flask import Flask, request, send_file\n",
    "import os\n",
    "import uuid\n",
    "import datetime\n",
    "\n",
    "\n",
    "from PIL import ImageFont\n",
    "\n",
    "# Use a default font provided by PIL\n",
    "font = ImageFont.load_default()\n",
    "\n",
    "# Alternatively, you can specify the font size\n",
    "font_with_size = ImageFont.load_default().font_variant(size=12)\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello_world():\n",
    "    a = \"Welcome!\"\n",
    "    return a\n",
    "\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload():\n",
    "    # Third-party API\n",
    "    image = request.files[\"image\"]\n",
    "    image_file = image.read()\n",
    "    image_size = 350\n",
    "    image = load_demo_image(image_file, image_size=image_size, device=device)\n",
    "    image.save(\"image.jpg\")\n",
    "\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     # Beam search\n",
    "    #     # caption = model.generate(image, sample=False, num_beams=9, max_length=20, min_length=5)\n",
    "    #     # Nucleus sampling\n",
    "    #     caption = model.generate(\n",
    "    #         image, sample=True, top_p=0.9, max_length=20, min_length=5\n",
    "    #     )\n",
    "    #     print(\"caption: \" + caption[0])\n",
    "    # text = caption[0]\n",
    "    import requests\n",
    "\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "    headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "    def query(filename):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            data = f.read()\n",
    "        response = requests.post(API_URL, headers=headers, data=data)\n",
    "        return response.json()\n",
    "\n",
    "    output = query(\"image.jpg\")\n",
    "\n",
    "    # Used to securely store your API key\n",
    "    import google.generativeai as genai\n",
    "\n",
    "    # Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "    genai.configure(api_key='AIzaSyBa5b8ZuK83ehPi52ua4Ly724ofJHTT5Zk')\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "    response = model.generate_content(f\"this is the description for photo '''{output[0]['generated_text']}''' write a 5- 10 word meme for it humor should be very nice\")\n",
    "    print(response.text)\n",
    "    # print(generated_text)\n",
    "\n",
    "    # Example usage\n",
    "    n = ImgText(response.text, image_file)\n",
    "    res = n.draw_text()\n",
    "    json_data = {\n",
    "        \"data\": \"https://nginx-web-fraork-njcq-uwcqowzevm.cn-chengdu.fcapp.run\" + res\n",
    "    }\n",
    "    json_img = json.dumps(json_data)\n",
    "    print(json_img)\n",
    "    return json_img\n",
    "\n",
    "\n",
    "def load_demo_image(image_file, image_size, device):\n",
    "    # Convert image to PIL Image object\n",
    "    image = Image.open(io.BytesIO(image_file))\n",
    "    # Convert image to RGB format\n",
    "    raw_image = image.convert(\"RGB\")\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(\n",
    "                (image_size, image_size), interpolation=InterpolationMode.BICUBIC\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                (0.48145466, 0.4578275, 0.40821073),\n",
    "                (0.26862954, 0.26130258, 0.27577711),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    image = transform(raw_image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Print tensor shape for debugging\n",
    "    print(f\"Image tensor shape: {image.shape}\")\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "class ImgText:\n",
    "    font = ImageFont.truetype(\"kuaikanshijieti.ttf\", 50)\n",
    "\n",
    "    def __init__(self, text, image):\n",
    "        img = Image.open(io.BytesIO(image))\n",
    "        width = img.size[0]\n",
    "        height = img.size[1]\n",
    "        print(width)\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.text = text\n",
    "        self.image = image\n",
    "        self.duanluo, self.note_height, self.line_height = self.split_text()\n",
    "\n",
    "    def get_paragraph(self, text):\n",
    "        txt = Image.new(\"RGBA\", (100, 100), (255, 255, 255, 0))\n",
    "        draw = ImageDraw.Draw(txt)\n",
    "        paragraphs = \"\"\n",
    "        total_width = 0\n",
    "        line_count = 1\n",
    "        line_height = 0\n",
    "        for char in text:\n",
    "            bbox = draw.textbbox((0, 0), char, font=ImgText.font)\n",
    "            width = bbox[2] - bbox[0]\n",
    "            height = bbox[3] - bbox[1]\n",
    "            total_width += width\n",
    "            if total_width > self.width:\n",
    "                line_count += 1\n",
    "                total_width = 0\n",
    "                paragraphs += \"/n\"\n",
    "            paragraphs += char\n",
    "            line_height = max(height, line_height)\n",
    "        if not paragraphs.endswith(\"/n\"):\n",
    "            paragraphs += \"/n\"\n",
    "        return paragraphs, line_height, line_count\n",
    "\n",
    "    def split_text(self):\n",
    "        max_line_height, total_lines = 0, 0\n",
    "        allText = []\n",
    "        for text in self.text.split(\"/n\"):\n",
    "            paragraph, line_height, line_count = self.get_paragraph(text)\n",
    "            max_line_height = max(line_height, max_line_height)\n",
    "            total_lines += line_count\n",
    "            allText.append((paragraph, line_count))\n",
    "        line_height = max_line_height\n",
    "        total_height = total_lines * line_height\n",
    "        return allText, total_height, line_height\n",
    "\n",
    "    def draw_text(self):\n",
    "        note_img = Image.open(io.BytesIO(self.image)).convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(note_img)\n",
    "        x, y = 0, int(self.height) / 2\n",
    "        for paragraph, line_count in self.duanluo:\n",
    "            draw.text((x + 2, y), paragraph, fill=(0, 0, 0), font=ImgText.font)\n",
    "            draw.text((x - 2, y), paragraph, fill=(255, 255, 255), font=ImgText.font)\n",
    "            draw.text((x, y + 2), paragraph, fill=(0, 0, 0), font=ImgText.font)\n",
    "            draw.text((x, y - 2), paragraph, fill=(255, 255, 255), font=ImgText.font)\n",
    "            y += self.line_height * line_count\n",
    "\n",
    "        today = datetime.date.today()\n",
    "\n",
    "        dir_name = today.strftime(\"%Y-%m-%d\")\n",
    "        dir_path = os.path.join(\"/home/BLIP/imagedir\", dir_name)\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.mkdir(dir_path)\n",
    "        else:\n",
    "            print(\"Directory already exists, skipping creation\")\n",
    "\n",
    "        filename = str(uuid.uuid4()) + \".jpg\"\n",
    "        note_img.save(\"./imagedir/\" + dir_name + \"/\" + filename)\n",
    "        os.chmod(\"./imagedir/\" + dir_name + \"/\" + filename, 0o777)\n",
    "        return \"/imagedir/\" + dir_name + \"/\" + filename\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def callu(number):\n",
    "        headers = {\n",
    "        'Authorization': \"sk-49l0jhdx24371l57ronsc74no6o2py5ghoa6wkczwcu7xd6z6kd99lwyk3nn6hvx69\"\n",
    "        }\n",
    "\n",
    "        # Data\n",
    "        data = {\n",
    "        'phone_number': \"+91\"+ number,\n",
    "        'task': \"\"\"Fantastic! To begin your crowdfunding campaign, head to the 'Campaigns' section and follow the prompts to create your campaign page. Should you have any specific questions or need assistance, feel free to ask, and I'll be here to help.\"\n",
    "\n",
    "**Regarding participation in crowdfunding campaigns, our platform typically allows all users to participate, provided they meet certain criteria, such as compliance with our community guidelines and any legal requirements applicable to crowdfunding activities. However, it's always a good idea to review the specific terms and conditions associated with each campaign to ensure eligibility and compliance.\"\n",
    "\n",
    "User: \"Thank you for your assistance. I'll start setting up my campaign now.\"\n",
    "\"I appreciate your help. I'll reach out if I have any further questions.\"\n",
    "\"I'm impressed with the features. I'll definitely recommend this app to others.\"\n",
    "\n",
    "AI:\n",
    "\"Great to hear! If you have any further questions or need assistance in the future, don't hesitate to reach out. We're here to support you every step of the way. Thank you for choosing Dsocial's decentralized social network app, leveraging blockchain technology for secure and transparent transactions. Have a wonderful day!\n",
    "\n",
    "User: \"How secure are P2P transfers on this app? Is my financial information safe?\"\n",
    "AI: \"Security is a top priority for us. Our platform utilizes advanced encryption and security measures to ensure the safety of your financial information during P2P transfers. Additionally, we adhere to strict privacy policies to protect your personal data.\"\n",
    "\n",
    "Customer Support:\n",
    "User: \"What should I do if I encounter an issue while using the app?\"\n",
    "AI: \"If you encounter any issues or have questions while using our app, you can reach out to our dedicated customer support team for assistance. We offer various support channels, including live chat, email, and a help center, to ensure that your concerns are addressed promptly.\"\n",
    "\n",
    "Integration with External Wallets:\n",
    "User: \"Can I link my external cryptocurrency wallet to this app for P2P transfers?\"\n",
    "AI: \"At the moment, our platform supports internal wallet transactions for P2P transfers. However, we're continuously exploring options for integrating external wallets to provide more flexibility for our users. Stay tuned for any updates on this feature!\"\n",
    "\n",
    "Rewards and Loyalty Programs:\n",
    "User: \"Does the app offer any rewards or loyalty programs for frequent users?\"\n",
    "AI: \"Yes, we value our users' loyalty and engagement. We have plans to introduce rewards and loyalty programs in the near future, offering incentives for active participation and contributions within our community. Keep an eye out for announcements about these programs!\"\n",
    "\n",
    "Future Development Roadmap:\n",
    "User: \"What new features or updates can we expect from the app in the future?\"\n",
    "AI: \"We're committed to continuous improvement and innovation. Our development team is working on several exciting features and updates, including enhanced social networking capabilities, expanded payment options, and integration with decentralized finance (DeFi) protocols. We'll keep our users informed about upcoming releases and developments.\"\"\",\n",
    "        'voice_id': 1,\n",
    "        'reduce_latency': True,\n",
    "        'request_data': {},\n",
    "        'voice_settings':{\n",
    "            \"speed\": \"0.8\"\n",
    "        },\n",
    "        'interruption_threshold': 0,\n",
    "        'start_time': None,\n",
    "        'transfer_phone_number': None,\n",
    "        'answered_by_enabled': False,\n",
    "        'from': None,\n",
    "        'first_sentence': None,\n",
    "        'record': True,\n",
    "        'max_duration': 2,\n",
    "        'model': 'enhanced',\n",
    "        'language': 'ENG',\n",
    "        }\n",
    "\n",
    "        # API request \n",
    "        requests.post('https://api.bland.ai/call', json=data, headers=headers)   \n",
    "        \n",
    "        return \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callu(\"9874233126\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
